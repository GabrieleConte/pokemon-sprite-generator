{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41af2f13",
   "metadata": {},
   "source": [
    "# Pokemon Sprite Generator - Three-Stage Training Pipeline\n",
    "\n",
    "## Overview\n",
    "This notebook implements a complete three-stage training pipeline for generating Pokemon sprites from text descriptions using a Stable Diffusion-like architecture.\n",
    "\n",
    "### Architecture Components:\n",
    "- **Stage 1**: VAE (Variational Autoencoder) with perceptual loss\n",
    "- **Stage 2**: U-Net diffusion model for denoising\n",
    "- **Stage 3**: Text encoder fine-tuning with frozen VAE and U-Net\n",
    "\n",
    "### Key Features:\n",
    "- ðŸŽ¨ Text-to-image generation for Pokemon sprites\n",
    "- ðŸ“Š TensorBoard logging for monitoring training progress\n",
    "- ðŸ”„ Modular three-stage training approach\n",
    "- ðŸš€ Optimized for Kaggle environment with GPU acceleration\n",
    "\n",
    "**Note**: This notebook is designed to work with the complete repository uploaded to Kaggle. Make sure to upload the entire `pokemon-sprite-generator` folder to your Kaggle dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf6ef26",
   "metadata": {},
   "source": [
    "# 1. Install Dependencies and Setup Environment\n",
    "\n",
    "First, let's install the required packages and set up the Python environment for the training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302e7d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package using pip\"\"\"\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "\n",
    "# Install required packages\n",
    "packages = [\n",
    "    'torch',\n",
    "    'torchvision',\n",
    "    'transformers',\n",
    "    'accelerate',\n",
    "    'tensorboard',\n",
    "    'pillow',\n",
    "    'matplotlib',\n",
    "    'seaborn',\n",
    "    'tqdm',\n",
    "    'pyyaml',\n",
    "    'numpy',\n",
    "    'pandas'\n",
    "]\n",
    "\n",
    "print(\"Installing required packages...\")\n",
    "for package in packages:\n",
    "    try:\n",
    "        install_package(package)\n",
    "        print(f\"âœ… {package} installed successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to install {package}: {e}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ All packages installed!\")\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"\\nGPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"Running on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9091e89a",
   "metadata": {},
   "source": [
    "# 2. Mount Kaggle Dataset and Configure Paths\n",
    "\n",
    "Set up the workspace by mounting the Pokemon dataset and configuring paths for the training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c24b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure paths for Kaggle environment\n",
    "KAGGLE_INPUT_PATH = \"/kaggle/input\"\n",
    "KAGGLE_WORKING_PATH = \"/kaggle/working\"\n",
    "\n",
    "# Repository path (adjust this based on your dataset name)\n",
    "REPO_NAME = \"pokemon-sprite-generator\"  # Change this to your actual dataset name\n",
    "REPO_PATH = Path(KAGGLE_INPUT_PATH) / REPO_NAME\n",
    "\n",
    "# Check if repository exists\n",
    "if REPO_PATH.exists():\n",
    "    print(f\"âœ… Repository found at: {REPO_PATH}\")\n",
    "    \n",
    "    # Copy repository to working directory for modifications\n",
    "    WORKING_REPO_PATH = Path(KAGGLE_WORKING_PATH) / REPO_NAME\n",
    "    if WORKING_REPO_PATH.exists():\n",
    "        shutil.rmtree(WORKING_REPO_PATH)\n",
    "    \n",
    "    shutil.copytree(REPO_PATH, WORKING_REPO_PATH)\n",
    "    print(f\"ðŸ“‚ Repository copied to: {WORKING_REPO_PATH}\")\n",
    "    \n",
    "    # Change to working directory\n",
    "    os.chdir(WORKING_REPO_PATH)\n",
    "    print(f\"ðŸ“ Current working directory: {os.getcwd()}\")\n",
    "    \n",
    "    # Add src to Python path\n",
    "    import sys\n",
    "    sys.path.insert(0, str(WORKING_REPO_PATH / \"src\"))\n",
    "    \n",
    "    # List repository contents\n",
    "    print(\"\\nðŸ“‹ Repository contents:\")\n",
    "    for item in sorted(WORKING_REPO_PATH.iterdir()):\n",
    "        if item.is_dir():\n",
    "            print(f\"  ðŸ“ {item.name}/\")\n",
    "        else:\n",
    "            print(f\"  ðŸ“„ {item.name}\")\n",
    "            \n",
    "else:\n",
    "    print(f\"âŒ Repository not found at: {REPO_PATH}\")\n",
    "    print(\"Please make sure you've uploaded the entire pokemon-sprite-generator repository as a Kaggle dataset.\")\n",
    "    print(\"\\nðŸ’¡ To upload the repository:\")\n",
    "    print(\"1. Zip the entire pokemon-sprite-generator folder\")\n",
    "    print(\"2. Upload it as a dataset on Kaggle\")\n",
    "    print(\"3. Update the REPO_NAME variable above with your dataset name\")\n",
    "\n",
    "# Configure experiment directory\n",
    "EXPERIMENT_DIR = Path(KAGGLE_WORKING_PATH) / \"experiments\"\n",
    "EXPERIMENT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\\nðŸ§ª Experiment directory: {EXPERIMENT_DIR}\")\n",
    "\n",
    "# Update config paths for Kaggle environment\n",
    "CONFIG_PATH = WORKING_REPO_PATH / \"config\" / \"train_config.yaml\"\n",
    "print(f\"âš™ï¸  Config file: {CONFIG_PATH}\")\n",
    "\n",
    "# Check if required files exist\n",
    "required_files = [\n",
    "    \"train_3stage.py\",\n",
    "    \"config/train_config.yaml\",\n",
    "    \"data/pokemon.csv\",\n",
    "    \"data/small_images\"\n",
    "]\n",
    "\n",
    "print(\"\\nðŸ” Checking required files:\")\n",
    "for file_path in required_files:\n",
    "    full_path = WORKING_REPO_PATH / file_path\n",
    "    if full_path.exists():\n",
    "        print(f\"  âœ… {file_path}\")\n",
    "    else:\n",
    "        print(f\"  âŒ {file_path} - NOT FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7771abfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update configuration for Kaggle environment\n",
    "import yaml\n",
    "\n",
    "# Read current config\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Update paths for Kaggle environment\n",
    "config['experiment_dir'] = str(EXPERIMENT_DIR)\n",
    "config['data']['csv_path'] = str(WORKING_REPO_PATH / \"data\" / \"pokemon.csv\")\n",
    "config['data']['image_dir'] = str(WORKING_REPO_PATH / \"data\" / \"small_images\")\n",
    "\n",
    "# Reduce batch size and epochs for Kaggle environment (optional)\n",
    "config['data']['batch_size'] = 8  # Reduce for memory efficiency\n",
    "config['data']['num_workers'] = 2  # Reduce for Kaggle\n",
    "\n",
    "# Adjust epochs for faster training on Kaggle\n",
    "config['training']['vae_epochs'] = 5\n",
    "config['training']['diffusion_epochs'] = 5\n",
    "config['training']['final_epochs'] = 3\n",
    "\n",
    "# Save updated config\n",
    "with open(CONFIG_PATH, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "print(\"âœ… Configuration updated for Kaggle environment\")\n",
    "print(f\"ðŸ“Š Batch size: {config['data']['batch_size']}\")\n",
    "print(f\"ðŸ”„ VAE epochs: {config['training']['vae_epochs']}\")\n",
    "print(f\"ðŸ”„ Diffusion epochs: {config['training']['diffusion_epochs']}\")\n",
    "print(f\"ðŸ”„ Final epochs: {config['training']['final_epochs']}\")\n",
    "print(f\"ðŸ“ Experiment directory: {config['experiment_dir']}\")\n",
    "print(f\"ðŸ“ Data directory: {config['data']['image_dir']}\")\n",
    "\n",
    "# Display updated config\n",
    "print(\"\\nâš™ï¸  Updated Configuration:\")\n",
    "print(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39022579",
   "metadata": {},
   "source": [
    "# 3. Load and Inspect Training Configuration\n",
    "\n",
    "Load the training configuration and display key parameters for each training stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b13b053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training configuration\n",
    "from src.training.vae_trainer import load_config\n",
    "import pandas as pd\n",
    "\n",
    "# Load configuration\n",
    "config = load_config(str(CONFIG_PATH))\n",
    "\n",
    "# Display key configuration parameters\n",
    "print(\"ðŸ”§ Model Configuration:\")\n",
    "print(f\"  â€¢ BERT model: {config['model']['bert_model']}\")\n",
    "print(f\"  â€¢ Text embedding dimension: {config['model']['text_embedding_dim']}\")\n",
    "print(f\"  â€¢ Latent dimension: {config['model']['latent_dim']}\")\n",
    "print(f\"  â€¢ Number of timesteps: {config['model']['num_timesteps']}\")\n",
    "\n",
    "print(\"\\nðŸ“Š Data Configuration:\")\n",
    "print(f\"  â€¢ Batch size: {config['data']['batch_size']}\")\n",
    "print(f\"  â€¢ Image size: {config['data']['image_size']}\")\n",
    "print(f\"  â€¢ Number of workers: {config['data']['num_workers']}\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Training Configuration:\")\n",
    "print(f\"  â€¢ VAE epochs: {config['training']['vae_epochs']}\")\n",
    "print(f\"  â€¢ Diffusion epochs: {config['training']['diffusion_epochs']}\")\n",
    "print(f\"  â€¢ Final epochs: {config['training']['final_epochs']}\")\n",
    "\n",
    "print(\"\\nâš–ï¸  Loss Configuration:\")\n",
    "print(f\"  â€¢ Reconstruction weight: {config['training']['reconstruction_weight']}\")\n",
    "print(f\"  â€¢ Perceptual weight: {config['training']['perceptual_weight']}\")\n",
    "print(f\"  â€¢ KL weight: {config['training']['kl_weight']}\")\n",
    "\n",
    "print(\"\\nðŸ”„ KL Annealing Configuration:\")\n",
    "print(f\"  â€¢ KL anneal start: {config['training']['kl_anneal_start']}\")\n",
    "print(f\"  â€¢ KL anneal end: {config['training']['kl_anneal_end']}\")\n",
    "print(f\"  â€¢ KL weight start: {config['training']['kl_weight_start']}\")\n",
    "print(f\"  â€¢ KL weight end: {config['training']['kl_weight_end']}\")\n",
    "\n",
    "print(\"\\nðŸŽ² Optimization Configuration:\")\n",
    "print(f\"  â€¢ Learning rate: {config['optimization']['learning_rate']}\")\n",
    "print(f\"  â€¢ Beta1: {config['optimization']['beta1']}\")\n",
    "print(f\"  â€¢ Beta2: {config['optimization']['beta2']}\")\n",
    "print(f\"  â€¢ Weight decay: {config['optimization']['weight_decay']}\")\n",
    "\n",
    "# Calculate estimated training time\n",
    "total_epochs = config['training']['vae_epochs'] + config['training']['diffusion_epochs'] + config['training']['final_epochs']\n",
    "print(f\"\\nâ±ï¸  Estimated Total Training:\")\n",
    "print(f\"  â€¢ Total epochs: {total_epochs}\")\n",
    "print(f\"  â€¢ Estimated time: ~{total_epochs * 10} minutes (approximate)\")\n",
    "\n",
    "# Display paths\n",
    "print(f\"\\nðŸ“ File Paths:\")\n",
    "print(f\"  â€¢ Config: {CONFIG_PATH}\")\n",
    "print(f\"  â€¢ Data CSV: {config['data']['csv_path']}\")\n",
    "print(f\"  â€¢ Images: {config['data']['image_dir']}\")\n",
    "print(f\"  â€¢ Experiments: {config['experiment_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190eeb5c",
   "metadata": {},
   "source": [
    "# 4. Dataset Statistics and Visualization\n",
    "\n",
    "Analyze dataset statistics, visualize Pokemon types distribution, and show sample images with descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d4ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze dataset statistics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from src.data import get_dataset_statistics\n",
    "\n",
    "# Load dataset statistics\n",
    "print(\"ðŸ“Š Computing dataset statistics...\")\n",
    "stats = get_dataset_statistics(\n",
    "    config['data']['csv_path'],\n",
    "    config['data']['image_dir']\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ“ˆ Dataset Statistics:\")\n",
    "print(f\"  â€¢ Total samples: {stats['total_samples']}\")\n",
    "print(f\"  â€¢ Average description length: {stats['avg_description_length']:.1f} words\")\n",
    "print(f\"  â€¢ Description length std: {stats['description_length_std']:.1f}\")\n",
    "\n",
    "# Load full dataset for visualization\n",
    "# Handle different encodings like the dataset classes\n",
    "try:\n",
    "    df = pd.read_csv(config['data']['csv_path'], sep='\\t', encoding='utf-16')\n",
    "except UnicodeDecodeError:\n",
    "    try:\n",
    "        df = pd.read_csv(config['data']['csv_path'], sep='\\t', encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(config['data']['csv_path'], sep='\\t', encoding='latin-1')\n",
    "\n",
    "print(f\"\\nðŸ“ Dataset columns: {list(df.columns)}\")\n",
    "print(f\"ðŸ“‹ First few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Visualize Pokemon types distribution\n",
    "if 'primary_type' in df.columns:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    type_counts = df['primary_type'].value_counts().head(15)\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.barplot(x=type_counts.values, y=type_counts.index)\n",
    "    plt.title('Top 15 Pokemon Types Distribution')\n",
    "    plt.xlabel('Count')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.pie(type_counts.values, labels=type_counts.index, autopct='%1.1f%%')\n",
    "    plt.title('Pokemon Types Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show sample images with descriptions\n",
    "print(\"\\nðŸ–¼ï¸  Sample Pokemon Images:\")\n",
    "sample_indices = np.random.choice(len(df), min(6, len(df)), replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    try:\n",
    "        # Load image\n",
    "        image_path = Path(config['data']['image_dir']) / f\"{df.iloc[idx]['national_number']:03d}.png\"\n",
    "        if image_path.exists():\n",
    "            img = Image.open(image_path)\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f\"#{df.iloc[idx]['national_number']} - {df.iloc[idx]['english_name']}\")\n",
    "            axes[i].axis('off')\n",
    "            \n",
    "            # Add description if available\n",
    "            if 'description' in df.columns and pd.notna(df.iloc[idx]['description']):\n",
    "                description = df.iloc[idx]['description'][:100] + \"...\" if len(df.iloc[idx]['description']) > 100 else df.iloc[idx]['description']\n",
    "                axes[i].text(0.5, -0.1, description, ha='center', va='top', \n",
    "                            transform=axes[i].transAxes, fontsize=8, wrap=True)\n",
    "        else:\n",
    "            axes[i].text(0.5, 0.5, f\"Image not found\\n{image_path}\", ha='center', va='center')\n",
    "            axes[i].set_title(f\"#{df.iloc[idx]['national_number']} - {df.iloc[idx]['english_name']}\")\n",
    "    except Exception as e:\n",
    "        axes[i].text(0.5, 0.5, f\"Error loading image: {e}\", ha='center', va='center')\n",
    "        axes[i].set_title(f\"Error - Index {idx}\")\n",
    "    \n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display description length distribution\n",
    "if 'description' in df.columns:\n",
    "    desc_lengths = df['description'].str.split().str.len()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(desc_lengths, bins=30, alpha=0.7, edgecolor='black')\n",
    "    plt.title('Distribution of Description Lengths')\n",
    "    plt.xlabel('Number of Words')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.axvline(desc_lengths.mean(), color='red', linestyle='--', label=f'Mean: {desc_lengths.mean():.1f}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "print(f\"\\nâœ… Dataset analysis complete!\")\n",
    "print(f\"Ready to start training with {len(df)} Pokemon samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9571a166",
   "metadata": {},
   "source": [
    "# 5. Stage 1: VAE Training with Perceptual Loss\n",
    "\n",
    "Execute the first stage of training - VAE (Variational Autoencoder) with perceptual loss for learning to encode/decode Pokemon images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feeda52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: VAE Training\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "\n",
    "print(\"ðŸš€ Starting Stage 1: VAE Training with Perceptual Loss\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Prepare training command\n",
    "train_cmd = [\n",
    "    sys.executable, \"train_3stage.py\",\n",
    "    \"--config\", str(CONFIG_PATH),\n",
    "    \"--stage\", \"1\",\n",
    "    \"--experiment-name\", \"kaggle_pokemon_3stage\"\n",
    "]\n",
    "\n",
    "print(f\"ðŸ’» Training command: {' '.join(train_cmd)}\")\n",
    "print(f\"ðŸ“ Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Start training\n",
    "start_time = time.time()\n",
    "try:\n",
    "    # Run training process\n",
    "    result = subprocess.run(train_cmd, capture_output=True, text=True, cwd=os.getcwd())\n",
    "    \n",
    "    print(\"ðŸ“‹ Training Output:\")\n",
    "    print(result.stdout)\n",
    "    \n",
    "    if result.stderr:\n",
    "        print(\"âš ï¸  Training Errors/Warnings:\")\n",
    "        print(result.stderr)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"âœ… Stage 1 training completed successfully!\")\n",
    "        \n",
    "        # Check if checkpoint was created\n",
    "        vae_checkpoint_path = Path(config['experiment_dir']) / \"kaggle_pokemon_3stage_vae\" / \"checkpoints\" / \"vae_best_model.pth\"\n",
    "        if vae_checkpoint_path.exists():\n",
    "            print(f\"ðŸŽ¯ VAE checkpoint saved at: {vae_checkpoint_path}\")\n",
    "            print(f\"ðŸ“ Checkpoint size: {vae_checkpoint_path.stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "        else:\n",
    "            print(\"âŒ VAE checkpoint not found!\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"âŒ Stage 1 training failed with return code: {result.returncode}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error during Stage 1 training: {e}\")\n",
    "    \n",
    "finally:\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"â±ï¸  Stage 1 training time: {training_time:.1f} seconds ({training_time/60:.1f} minutes)\")\n",
    "\n",
    "# Display training logs location\n",
    "logs_dir = Path(config['experiment_dir']) / \"kaggle_pokemon_3stage_vae\" / \"logs\"\n",
    "if logs_dir.exists():\n",
    "    print(f\"\\nðŸ“Š Training logs available at: {logs_dir}\")\n",
    "    print(\"You can view tensorboard logs by running:\")\n",
    "    print(f\"tensorboard --logdir {logs_dir}\")\n",
    "else:\n",
    "    print(\"âš ï¸  No training logs found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5fe185",
   "metadata": {},
   "source": [
    "# 6. Stage 2: U-Net Diffusion Training\n",
    "\n",
    "Execute the second stage of training - U-Net diffusion model for denoising using the trained VAE from Stage 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c71014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2: U-Net Diffusion Training\n",
    "print(\"ðŸš€ Starting Stage 2: U-Net Diffusion Training\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if VAE checkpoint exists\n",
    "vae_checkpoint_path = Path(config['experiment_dir']) / \"kaggle_pokemon_3stage_vae\" / \"checkpoints\" / \"vae_best_model.pth\"\n",
    "\n",
    "if not vae_checkpoint_path.exists():\n",
    "    print(\"âŒ VAE checkpoint not found! Please run Stage 1 first.\")\n",
    "    print(f\"Expected path: {vae_checkpoint_path}\")\n",
    "else:\n",
    "    print(f\"âœ… VAE checkpoint found: {vae_checkpoint_path}\")\n",
    "    \n",
    "    # Prepare training command\n",
    "    train_cmd = [\n",
    "        sys.executable, \"train_3stage.py\",\n",
    "        \"--config\", str(CONFIG_PATH),\n",
    "        \"--stage\", \"2\",\n",
    "        \"--experiment-name\", \"kaggle_pokemon_3stage\",\n",
    "        \"--vae-checkpoint\", str(vae_checkpoint_path)\n",
    "    ]\n",
    "    \n",
    "    print(f\"ðŸ’» Training command: {' '.join(train_cmd)}\")\n",
    "    \n",
    "    # Start training\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        # Run training process\n",
    "        result = subprocess.run(train_cmd, capture_output=True, text=True, cwd=os.getcwd())\n",
    "        \n",
    "        print(\"ðŸ“‹ Training Output:\")\n",
    "        print(result.stdout)\n",
    "        \n",
    "        if result.stderr:\n",
    "            print(\"âš ï¸  Training Errors/Warnings:\")\n",
    "            print(result.stderr)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"âœ… Stage 2 training completed successfully!\")\n",
    "            \n",
    "            # Check if checkpoint was created\n",
    "            diffusion_checkpoint_path = Path(config['experiment_dir']) / \"kaggle_pokemon_3stage_diffusion\" / \"checkpoints\" / \"diffusion_best_model.pth\"\n",
    "            if diffusion_checkpoint_path.exists():\n",
    "                print(f\"ðŸŽ¯ Diffusion checkpoint saved at: {diffusion_checkpoint_path}\")\n",
    "                print(f\"ðŸ“ Checkpoint size: {diffusion_checkpoint_path.stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "            else:\n",
    "                print(\"âŒ Diffusion checkpoint not found!\")\n",
    "                \n",
    "        else:\n",
    "            print(f\"âŒ Stage 2 training failed with return code: {result.returncode}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during Stage 2 training: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "        print(f\"â±ï¸  Stage 2 training time: {training_time:.1f} seconds ({training_time/60:.1f} minutes)\")\n",
    "\n",
    "    # Display training logs location\n",
    "    logs_dir = Path(config['experiment_dir']) / \"kaggle_pokemon_3stage_diffusion\" / \"logs\"\n",
    "    if logs_dir.exists():\n",
    "        print(f\"\\nðŸ“Š Training logs available at: {logs_dir}\")\n",
    "    else:\n",
    "        print(\"âš ï¸  No training logs found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81704d31",
   "metadata": {},
   "source": [
    "# 7. Stage 3: Final Training (Text Encoder Fine-tuning)\n",
    "\n",
    "Execute the final stage of training - fine-tune the text encoder with frozen VAE and U-Net models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a27365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3: Final Training (Text Encoder Fine-tuning)\n",
    "print(\"ðŸš€ Starting Stage 3: Final Training (Text Encoder Fine-tuning)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if required checkpoints exist\n",
    "vae_checkpoint_path = Path(config['experiment_dir']) / \"kaggle_pokemon_3stage_vae\" / \"checkpoints\" / \"vae_best_model.pth\"\n",
    "diffusion_checkpoint_path = Path(config['experiment_dir']) / \"kaggle_pokemon_3stage_diffusion\" / \"checkpoints\" / \"diffusion_best_model.pth\"\n",
    "\n",
    "missing_checkpoints = []\n",
    "if not vae_checkpoint_path.exists():\n",
    "    missing_checkpoints.append(f\"VAE checkpoint: {vae_checkpoint_path}\")\n",
    "if not diffusion_checkpoint_path.exists():\n",
    "    missing_checkpoints.append(f\"Diffusion checkpoint: {diffusion_checkpoint_path}\")\n",
    "\n",
    "if missing_checkpoints:\n",
    "    print(\"âŒ Required checkpoints not found:\")\n",
    "    for checkpoint in missing_checkpoints:\n",
    "        print(f\"  â€¢ {checkpoint}\")\n",
    "    print(\"Please run previous stages first.\")\n",
    "else:\n",
    "    print(f\"âœ… VAE checkpoint found: {vae_checkpoint_path}\")\n",
    "    print(f\"âœ… Diffusion checkpoint found: {diffusion_checkpoint_path}\")\n",
    "    \n",
    "    # Prepare training command\n",
    "    train_cmd = [\n",
    "        sys.executable, \"train_3stage.py\",\n",
    "        \"--config\", str(CONFIG_PATH),\n",
    "        \"--stage\", \"3\",\n",
    "        \"--experiment-name\", \"kaggle_pokemon_3stage\",\n",
    "        \"--vae-checkpoint\", str(vae_checkpoint_path),\n",
    "        \"--diffusion-checkpoint\", str(diffusion_checkpoint_path)\n",
    "    ]\n",
    "    \n",
    "    print(f\"ðŸ’» Training command: {' '.join(train_cmd)}\")\n",
    "    \n",
    "    # Start training\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        # Run training process\n",
    "        result = subprocess.run(train_cmd, capture_output=True, text=True, cwd=os.getcwd())\n",
    "        \n",
    "        print(\"ðŸ“‹ Training Output:\")\n",
    "        print(result.stdout)\n",
    "        \n",
    "        if result.stderr:\n",
    "            print(\"âš ï¸  Training Errors/Warnings:\")\n",
    "            print(result.stderr)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"âœ… Stage 3 training completed successfully!\")\n",
    "            \n",
    "            # Check if checkpoint was created\n",
    "            final_checkpoint_path = Path(config['experiment_dir']) / \"kaggle_pokemon_3stage_final\" / \"checkpoints\" / \"final_best_model.pth\"\n",
    "            if final_checkpoint_path.exists():\n",
    "                print(f\"ðŸŽ¯ Final checkpoint saved at: {final_checkpoint_path}\")\n",
    "                print(f\"ðŸ“ Checkpoint size: {final_checkpoint_path.stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "            else:\n",
    "                print(\"âŒ Final checkpoint not found!\")\n",
    "                \n",
    "        else:\n",
    "            print(f\"âŒ Stage 3 training failed with return code: {result.returncode}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during Stage 3 training: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "        print(f\"â±ï¸  Stage 3 training time: {training_time:.1f} seconds ({training_time/60:.1f} minutes)\")\n",
    "\n",
    "    # Display training logs location\n",
    "    logs_dir = Path(config['experiment_dir']) / \"kaggle_pokemon_3stage_final\" / \"logs\"\n",
    "    if logs_dir.exists():\n",
    "        print(f\"\\nðŸ“Š Training logs available at: {logs_dir}\")\n",
    "    else:\n",
    "        print(\"âš ï¸  No training logs found\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ All training stages completed!\")\n",
    "print(\"Your Pokemon sprite generator is ready for inference!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb33667",
   "metadata": {},
   "source": [
    "# 8. Monitor Training Progress and Logs\n",
    "\n",
    "Display training logs, loss curves, and generated sample images throughout the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc09ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor training progress and logs\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "experiment_base = Path(config['experiment_dir'])\n",
    "stages = ['vae', 'diffusion', 'final']\n",
    "\n",
    "print(\"ðŸ“Š Training Progress Summary\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for stage in stages:\n",
    "    stage_dir = experiment_base / f\"kaggle_pokemon_3stage_{stage}\"\n",
    "    \n",
    "    if stage_dir.exists():\n",
    "        print(f\"\\nðŸ” {stage.upper()} Stage:\")\n",
    "        \n",
    "        # Check for checkpoints\n",
    "        checkpoint_dir = stage_dir / \"checkpoints\"\n",
    "        if checkpoint_dir.exists():\n",
    "            checkpoints = list(checkpoint_dir.glob(\"*.pth\"))\n",
    "            if checkpoints:\n",
    "                print(f\"  âœ… Checkpoints found: {len(checkpoints)}\")\n",
    "                for checkpoint in checkpoints:\n",
    "                    size_mb = checkpoint.stat().st_size / 1024 / 1024\n",
    "                    print(f\"    â€¢ {checkpoint.name}: {size_mb:.1f} MB\")\n",
    "            else:\n",
    "                print(\"  âŒ No checkpoints found\")\n",
    "        else:\n",
    "            print(\"  âŒ No checkpoint directory found\")\n",
    "        \n",
    "        # Check for logs\n",
    "        log_dir = stage_dir / \"logs\"\n",
    "        if log_dir.exists():\n",
    "            log_files = list(log_dir.glob(\"**/*\"))\n",
    "            if log_files:\n",
    "                print(f\"  ðŸ“‹ Log files found: {len(log_files)}\")\n",
    "                print(f\"    Location: {log_dir}\")\n",
    "            else:\n",
    "                print(\"  âŒ No log files found\")\n",
    "        else:\n",
    "            print(\"  âŒ No log directory found\")\n",
    "        \n",
    "        # Check for sample images\n",
    "        sample_dir = stage_dir / \"samples\"\n",
    "        if sample_dir.exists():\n",
    "            sample_files = list(sample_dir.glob(\"*.png\"))\n",
    "            if sample_files:\n",
    "                print(f\"  ðŸ–¼ï¸  Sample images found: {len(sample_files)}\")\n",
    "                \n",
    "                # Display latest sample images\n",
    "                sample_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "                latest_samples = sample_files[:3]  # Show 3 latest samples\n",
    "                \n",
    "                if latest_samples:\n",
    "                    print(f\"  ðŸ“¸ Latest sample images:\")\n",
    "                    fig, axes = plt.subplots(1, min(3, len(latest_samples)), figsize=(12, 4))\n",
    "                    if len(latest_samples) == 1:\n",
    "                        axes = [axes]\n",
    "                    \n",
    "                    for i, sample_path in enumerate(latest_samples):\n",
    "                        try:\n",
    "                            img = Image.open(sample_path)\n",
    "                            axes[i].imshow(img)\n",
    "                            axes[i].set_title(f\"{sample_path.name}\")\n",
    "                            axes[i].axis('off')\n",
    "                        except Exception as e:\n",
    "                            axes[i].text(0.5, 0.5, f\"Error: {e}\", ha='center', va='center')\n",
    "                            axes[i].set_title(f\"Error loading {sample_path.name}\")\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "            else:\n",
    "                print(\"  âŒ No sample images found\")\n",
    "        else:\n",
    "            print(\"  âŒ No sample directory found\")\n",
    "    else:\n",
    "        print(f\"\\nâŒ {stage.upper()} Stage: Directory not found\")\n",
    "\n",
    "# Display recent log entries for debugging\n",
    "print(\"\\nðŸ“‹ Recent Training Logs:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for stage in stages:\n",
    "    stage_dir = experiment_base / f\"kaggle_pokemon_3stage_{stage}\"\n",
    "    log_dir = stage_dir / \"logs\"\n",
    "    \n",
    "    if log_dir.exists():\n",
    "        # Find the most recent log file\n",
    "        log_files = list(log_dir.glob(\"**/*\"))\n",
    "        if log_files:\n",
    "            print(f\"\\nðŸ“‚ {stage.upper()} Stage Logs:\")\n",
    "            print(f\"  Log directory: {log_dir}\")\n",
    "            \n",
    "            # You can add more specific log parsing here if needed\n",
    "            # For now, just show the directory structure\n",
    "            for log_file in sorted(log_files)[:5]:  # Show first 5 log files\n",
    "                if log_file.is_file():\n",
    "                    size_kb = log_file.stat().st_size / 1024\n",
    "                    print(f\"    â€¢ {log_file.name}: {size_kb:.1f} KB\")\n",
    "\n",
    "print(\"\\nâœ… Training monitoring complete!\")\n",
    "print(\"\\nðŸ’¡ To view detailed training logs, you can:\")\n",
    "print(\"1. Check the tensorboard logs in each stage's logs directory\")\n",
    "print(\"2. Examine the checkpoint files for model weights\")\n",
    "print(\"3. Look at sample images generated during training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eb5ad6",
   "metadata": {},
   "source": [
    "# 9. Save and Export Model Checkpoints\n",
    "\n",
    "Save final model checkpoints and prepare them for download or further use in inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd2a264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and export model checkpoints\n",
    "import zipfile\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"ðŸ’¾ Preparing Model Checkpoints for Export\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create export directory\n",
    "export_dir = Path(KAGGLE_WORKING_PATH) / \"pokemon_generator_export\"\n",
    "export_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Copy essential files\n",
    "essential_files = [\n",
    "    \"train_3stage.py\",\n",
    "    \"generate_pokemon_3stage.py\",\n",
    "    \"config/train_config.yaml\",\n",
    "    \"requirements.txt\",\n",
    "    \"README.md\"\n",
    "]\n",
    "\n",
    "print(\"ðŸ“‹ Copying essential files...\")\n",
    "for file_path in essential_files:\n",
    "    src = WORKING_REPO_PATH / file_path\n",
    "    if src.exists():\n",
    "        dst = export_dir / file_path\n",
    "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy2(src, dst)\n",
    "        print(f\"  âœ… {file_path}\")\n",
    "    else:\n",
    "        print(f\"  âŒ {file_path} - not found\")\n",
    "\n",
    "# Copy src directory\n",
    "src_dir = WORKING_REPO_PATH / \"src\"\n",
    "if src_dir.exists():\n",
    "    dst_src = export_dir / \"src\"\n",
    "    if dst_src.exists():\n",
    "        shutil.rmtree(dst_src)\n",
    "    shutil.copytree(src_dir, dst_src)\n",
    "    print(\"  âœ… src/\")\n",
    "\n",
    "# Copy trained model checkpoints\n",
    "checkpoint_info = []\n",
    "model_checkpoints = [\n",
    "    (\"vae\", \"kaggle_pokemon_3stage_vae/checkpoints/vae_best_model.pth\"),\n",
    "    (\"diffusion\", \"kaggle_pokemon_3stage_diffusion/checkpoints/diffusion_best_model.pth\"),\n",
    "    (\"final\", \"kaggle_pokemon_3stage_final/checkpoints/final_best_model.pth\")\n",
    "]\n",
    "\n",
    "print(\"\\nðŸŽ¯ Copying trained model checkpoints...\")\n",
    "checkpoints_dir = export_dir / \"checkpoints\"\n",
    "checkpoints_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for model_name, checkpoint_path in model_checkpoints:\n",
    "    src_checkpoint = Path(config['experiment_dir']) / checkpoint_path\n",
    "    if src_checkpoint.exists():\n",
    "        dst_checkpoint = checkpoints_dir / f\"{model_name}_best_model.pth\"\n",
    "        shutil.copy2(src_checkpoint, dst_checkpoint)\n",
    "        size_mb = dst_checkpoint.stat().st_size / 1024 / 1024\n",
    "        checkpoint_info.append(f\"{model_name}: {size_mb:.1f} MB\")\n",
    "        print(f\"  âœ… {model_name}_best_model.pth ({size_mb:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"  âŒ {model_name}_best_model.pth - not found\")\n",
    "\n",
    "# Create inference script\n",
    "inference_script = export_dir / \"inference_example.py\"\n",
    "inference_code = '''#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Example inference script for Pokemon sprite generation.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(str(Path(__file__).parent / \"src\"))\n",
    "\n",
    "from generate_pokemon_3stage import PokemonGenerator\n",
    "\n",
    "def generate_pokemon(description, output_path=\"generated_pokemon.png\"):\n",
    "    \"\"\"Generate a Pokemon sprite from text description.\"\"\"\n",
    "    \n",
    "    # Paths to trained models\n",
    "    vae_checkpoint = \"checkpoints/vae_best_model.pth\"\n",
    "    diffusion_checkpoint = \"checkpoints/diffusion_best_model.pth\"\n",
    "    config_path = \"config/train_config.yaml\"\n",
    "    \n",
    "    # Check if files exist\n",
    "    for path in [vae_checkpoint, diffusion_checkpoint, config_path]:\n",
    "        if not Path(path).exists():\n",
    "            print(f\"Error: {path} not found!\")\n",
    "            return None\n",
    "    \n",
    "    # Initialize generator\n",
    "    generator = PokemonGenerator(\n",
    "        vae_checkpoint_path=vae_checkpoint,\n",
    "        diffusion_checkpoint_path=diffusion_checkpoint,\n",
    "        config_path=config_path,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "    \n",
    "    # Generate image\n",
    "    image = generator.generate([description], num_inference_steps=50)[0]\n",
    "    \n",
    "    # Save image\n",
    "    generator.save_image(image, output_path)\n",
    "    print(f\"Generated Pokemon saved to: {output_path}\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    descriptions = [\n",
    "        \"A fire-type Pokemon with orange flames and wings\",\n",
    "        \"A water-type Pokemon with blue scales and fins\",\n",
    "        \"An electric-type Pokemon with yellow fur and lightning bolts\"\n",
    "    ]\n",
    "    \n",
    "    for i, desc in enumerate(descriptions):\n",
    "        output_file = f\"generated_pokemon_{i+1}.png\"\n",
    "        generate_pokemon(desc, output_file)\n",
    "'''\n",
    "\n",
    "with open(inference_script, 'w') as f:\n",
    "    f.write(inference_code)\n",
    "\n",
    "print(f\"  âœ… inference_example.py created\")\n",
    "\n",
    "# Create README for export\n",
    "readme_content = f'''# Pokemon Sprite Generator - Trained Models\n",
    "\n",
    "This package contains the trained Pokemon sprite generator models and inference code.\n",
    "\n",
    "## Training Information\n",
    "- Training Date: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "- Training Platform: Kaggle\n",
    "- Model Architecture: 3-Stage VAE + U-Net Diffusion\n",
    "\n",
    "## Model Checkpoints\n",
    "{chr(10).join(f\"- {info}\" for info in checkpoint_info)}\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "1. Install requirements:\n",
    "```bash\n",
    "pip install torch torchvision transformers pillow pyyaml numpy\n",
    "```\n",
    "\n",
    "2. Run inference:\n",
    "```python\n",
    "python inference_example.py\n",
    "```\n",
    "\n",
    "3. Or use the generator directly:\n",
    "```python\n",
    "from generate_pokemon_3stage import PokemonGenerator\n",
    "\n",
    "generator = PokemonGenerator(\n",
    "    vae_checkpoint_path=\"checkpoints/vae_best_model.pth\",\n",
    "    diffusion_checkpoint_path=\"checkpoints/diffusion_best_model.pth\",\n",
    "    config_path=\"config/train_config.yaml\"\n",
    ")\n",
    "\n",
    "image = generator.generate([\"A fire-type Pokemon with orange flames\"])\n",
    "```\n",
    "\n",
    "## Files Structure\n",
    "- `checkpoints/`: Trained model weights\n",
    "- `src/`: Source code for models and training\n",
    "- `config/`: Configuration files\n",
    "- `inference_example.py`: Example inference script\n",
    "- `generate_pokemon_3stage.py`: Main generation script\n",
    "- `train_3stage.py`: Training script\n",
    "\n",
    "## Training Stages\n",
    "1. **VAE Stage**: Variational Autoencoder with perceptual loss\n",
    "2. **Diffusion Stage**: U-Net denoising model\n",
    "3. **Final Stage**: Text encoder fine-tuning\n",
    "\n",
    "Enjoy generating Pokemon sprites! ðŸŽ®âœ¨\n",
    "'''\n",
    "\n",
    "readme_path = export_dir / \"README.md\"\n",
    "with open(readme_path, 'w') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(f\"  âœ… README.md created\")\n",
    "\n",
    "# Create zip file for download\n",
    "zip_path = Path(KAGGLE_WORKING_PATH) / \"pokemon_generator_trained.zip\"\n",
    "print(f\"\\nðŸ“¦ Creating zip file: {zip_path}\")\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for root, dirs, files in os.walk(export_dir):\n",
    "        for file in files:\n",
    "            file_path = Path(root) / file\n",
    "            arc_path = file_path.relative_to(export_dir)\n",
    "            zipf.write(file_path, arc_path)\n",
    "\n",
    "zip_size_mb = zip_path.stat().st_size / 1024 / 1024\n",
    "print(f\"âœ… Zip file created: {zip_size_mb:.1f} MB\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\nðŸŽ‰ Export Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ðŸ“ Export directory: {export_dir}\")\n",
    "print(f\"ðŸ“¦ Zip file: {zip_path}\")\n",
    "print(f\"ðŸ’¾ Total size: {zip_size_mb:.1f} MB\")\n",
    "print(\"\\nYou can now download the zip file containing:\")\n",
    "print(\"â€¢ Trained model checkpoints\")\n",
    "print(\"â€¢ Complete source code\")\n",
    "print(\"â€¢ Configuration files\")\n",
    "print(\"â€¢ Example inference script\")\n",
    "print(\"â€¢ Documentation\")\n",
    "\n",
    "# Display final directory structure\n",
    "print(f\"\\nðŸ“‹ Export Contents:\")\n",
    "for root, dirs, files in os.walk(export_dir):\n",
    "    level = root.replace(str(export_dir), '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files:\n",
    "        file_path = Path(root) / file\n",
    "        size_kb = file_path.stat().st_size / 1024\n",
    "        print(f\"{subindent}{file} ({size_kb:.1f} KB)\")\n",
    "\n",
    "print(\"\\nðŸš€ Ready for Pokemon generation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0115c9",
   "metadata": {},
   "source": [
    "# 10. Test the Trained Model\n",
    "\n",
    "Test the complete trained model by generating Pokemon sprites from text descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad48f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model\n",
    "try:\n",
    "    # Import the generation script\n",
    "    from generate_pokemon_3stage import PokemonGenerator\n",
    "    \n",
    "    print(\"ðŸ§ª Testing Trained Pokemon Generator\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check if all required checkpoints exist\n",
    "    required_checkpoints = [\n",
    "        Path(config['experiment_dir']) / \"kaggle_pokemon_3stage_vae\" / \"checkpoints\" / \"vae_best_model.pth\",\n",
    "        Path(config['experiment_dir']) / \"kaggle_pokemon_3stage_diffusion\" / \"checkpoints\" / \"diffusion_best_model.pth\"\n",
    "    ]\n",
    "    \n",
    "    all_checkpoints_exist = all(checkpoint.exists() for checkpoint in required_checkpoints)\n",
    "    \n",
    "    if not all_checkpoints_exist:\n",
    "        print(\"âŒ Some required checkpoints are missing:\")\n",
    "        for checkpoint in required_checkpoints:\n",
    "            status = \"âœ…\" if checkpoint.exists() else \"âŒ\"\n",
    "            print(f\"  {status} {checkpoint}\")\n",
    "        print(\"Please ensure all training stages completed successfully.\")\n",
    "    else:\n",
    "        print(\"âœ… All required checkpoints found!\")\n",
    "        \n",
    "        # Initialize the generator\n",
    "        print(\"\\nðŸš€ Initializing Pokemon Generator...\")\n",
    "        generator = PokemonGenerator(\n",
    "            vae_checkpoint_path=str(required_checkpoints[0]),\n",
    "            diffusion_checkpoint_path=str(required_checkpoints[1]),\n",
    "            config_path=str(CONFIG_PATH),\n",
    "            device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        \n",
    "        # Test descriptions\n",
    "        test_descriptions = [\n",
    "            \"A fire-type Pokemon with orange flames and wings\",\n",
    "            \"A water-type Pokemon with blue scales and fins\", \n",
    "            \"An electric-type Pokemon with yellow fur and lightning bolts\",\n",
    "            \"A grass-type Pokemon with green leaves and vines\",\n",
    "            \"A psychic-type Pokemon with purple aura and mystic powers\"\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nðŸŽ¨ Generating {len(test_descriptions)} Pokemon sprites...\")\n",
    "        \n",
    "        # Generate images\n",
    "        fig, axes = plt.subplots(1, len(test_descriptions), figsize=(20, 4))\n",
    "        if len(test_descriptions) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for i, description in enumerate(test_descriptions):\n",
    "            print(f\"  ðŸŽ¯ Generating: {description}\")\n",
    "            \n",
    "            try:\n",
    "                # Generate image\n",
    "                images = generator.generate([description], num_inference_steps=25)\n",
    "                \n",
    "                # Display image\n",
    "                if images and len(images) > 0:\n",
    "                    # The generator returns PIL Images, so we can display them directly\n",
    "                    image = images[0]\n",
    "                    \n",
    "                    # Handle both PIL Images and tensors\n",
    "                    if hasattr(image, 'size'):  # PIL Image\n",
    "                        axes[i].imshow(image)\n",
    "                    else:  # Tensor\n",
    "                        if image.dim() == 3:\n",
    "                            image_array = image.permute(1, 2, 0).cpu().numpy()\n",
    "                            image_array = np.clip(image_array, 0, 1)\n",
    "                        else:\n",
    "                            image_array = image.cpu().numpy()\n",
    "                        axes[i].imshow(image_array)\n",
    "                    \n",
    "                    axes[i].set_title(f\"Pokemon #{i+1}\", fontsize=10)\n",
    "                    axes[i].axis('off')\n",
    "                    \n",
    "                    # Add description below image\n",
    "                    wrapped_desc = description[:30] + \"\\n\" + description[30:] if len(description) > 30 else description\n",
    "                    axes[i].text(0.5, -0.15, wrapped_desc, ha='center', va='top', \n",
    "                                transform=axes[i].transAxes, fontsize=8, wrap=True)\n",
    "                    \n",
    "                    print(f\"    âœ… Generated successfully\")\n",
    "                    \n",
    "                else:\n",
    "                    axes[i].text(0.5, 0.5, \"Generation\\nFailed\", ha='center', va='center')\n",
    "                    axes[i].set_title(f\"Pokemon #{i+1} - Error\")\n",
    "                    axes[i].axis('off')\n",
    "                    print(f\"    âŒ Generation failed\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                axes[i].text(0.5, 0.5, f\"Error:\\n{str(e)[:50]}...\", ha='center', va='center')\n",
    "                axes[i].set_title(f\"Pokemon #{i+1} - Error\")\n",
    "                axes[i].axis('off')\n",
    "                print(f\"    âŒ Error: {e}\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nðŸŽ‰ Generation test completed!\")\n",
    "        print(\"The trained model is ready for use!\")\n",
    "        \n",
    "        # Save one example image\n",
    "        try:\n",
    "            example_images = generator.generate([\"A cute electric-type Pokemon with yellow fur\"], num_inference_steps=50)\n",
    "            if example_images and len(example_images) > 0:\n",
    "                # Save PIL Image directly\n",
    "                example_image = example_images[0]\n",
    "                if hasattr(example_image, 'save'):  # PIL Image\n",
    "                    example_image.save(\"final_test_pokemon.png\")\n",
    "                    print(f\"ðŸ’¾ Example image saved as: final_test_pokemon.png\")\n",
    "                else:\n",
    "                    print(\"âŒ Generated image is not in a saveable format\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error saving example image: {e}\")\n",
    "            \n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")\n",
    "    print(\"This might be due to missing dependencies or incomplete training.\")\n",
    "    print(\"Please ensure all training stages completed successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error during testing: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\nðŸ Training and Testing Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"ðŸŽ® Your Pokemon Sprite Generator is ready to use!\")\n",
    "print(\"ðŸ“¦ Download the zip file created in the previous section\")\n",
    "print(\"ðŸš€ Use the inference_example.py script for generating new Pokemon\")\n",
    "print(\"âœ¨ Have fun creating your own Pokemon sprites!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
